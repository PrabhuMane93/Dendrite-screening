{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18acaea2-62b3-49c3-abd7-d17f3b008352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6447d-d2fd-4296-adb8-331251dc4b51",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6fa37a0-a927-4b17-8dc5-50f4f689c0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_hash(df, column_name):\n",
    "    #tokenize the text column\n",
    "    tokens = df[column_name].apply(word_tokenize)\n",
    "    #hash the tokens\n",
    "    hash_vectorizer = HashingVectorizer(n_features=5)       #Default number of columns for tokenization is 5\n",
    "    hashed_features = hash_vectorizer.transform(tokens.apply(' '.join))\n",
    "    hashed_df = pd.DataFrame(hashed_features.toarray(), columns=[f'{column_name}_feature_{i+1}' for i in range(5)])\n",
    "    #replace the text columns with newly created hashs\n",
    "    df = df.drop(columns = [column_name])\n",
    "    return pd.concat([df, hashed_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f2a4d5b-19a1-402f-99df-8200e8942b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(df, features):\n",
    "    for i in features:\n",
    "        if features[i][\"is_selected\"]:\n",
    "            if features[i][\"feature_variable_type\"]==\"numerical\":\n",
    "                df[i] = pd.to_numeric(df[i])\n",
    "                if features[i][\"feature_details\"][\"impute_with\"]==\"Average of values\":\n",
    "                    mean  = df[i].mean()\n",
    "                    df[i] = df[i].fillna(mean)\n",
    "                else:\n",
    "                    df[i] = df[i].fillna(int(features[i][\"feature_details\"][\"impute_value\"]))\n",
    "           \n",
    "            if features[i][\"feature_variable_type\"]==\"text\":\n",
    "                df = tokenize_and_hash(df, i)\n",
    "        else:\n",
    "            df = df.drop(columns=[i])   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bac6af8f-f66d-46a8-9f78-3b0ad5ab24f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "def reduce(target, df, reduction_dictionary):\n",
    "\n",
    "    if reduction_dictionary[\"feature_reduction_method\"] == \"Correlation with target\":\n",
    "        num_of_features_to_keep = reduction_dictionary[\"num_of_features_to_keep\"]\n",
    "        correlations = df.corr()[target]\n",
    "        sorted_features = correlations.abs().sort_values(ascending=False)\n",
    "        top_features = sorted_features.head(int(num_of_features_to_keep)+1).index\n",
    "        new_df = df[top_features]\n",
    "        new_df[target] = df[target]\n",
    "        return new_df\n",
    "\n",
    "    elif reduction_dictionary[\"feature_reduction_method\"] == \"Tree-based\":\n",
    "        num_of_features_to_keep = reduction_dictionary[\"num_of_features_to_keep\"]\n",
    "        depth_of_trees = reduction_dictionary[\"depth_of_trees\"]\n",
    "        num_of_trees = reduction_dictionary[\"num_of_trees\"]\n",
    "        model = RandomForestRegressor(n_estimators = int(num_of_trees), max_depth = int(depth_of_trees))\n",
    "        model.fit(df.drop(columns = [target]).values, df[target].values)\n",
    "        feature_importance = model.feature_importances_\n",
    "        sorted_indices = feature_importance.argsort()[::-1]\n",
    "        sorted_features = df.drop(columns = [target]).columns[sorted_indices]\n",
    "        selected_features = sorted_features[:int(num_of_features_to_keep)]\n",
    "        new_df = df[selected_features]\n",
    "        new_df[target] = df[target]\n",
    "        return new_df\n",
    "    \n",
    "    elif reduction_dictionary[\"feature_reduction_method\"] == \"Principal Component Analysis\":\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(df.drop(columns = [target]).values)\n",
    "        pca = PCA(n_components=int(reduction_dictionary[\"num_of_features_to_keep\"]))\n",
    "        pca_result = pca.fit_transform(scaled_data)\n",
    "        components = pca.components_\n",
    "        new_column_names = [f'PC{i+1}' for i in range(int(reduction_dictionary[\"num_of_features_to_keep\"]))]\n",
    "        pca_df = pd.DataFrame(data=pca_result, columns=new_column_names)\n",
    "        pca_df[target] = df[target]\n",
    "        return pca_df\n",
    "\n",
    "    elif reduction_dictionary[\"feature_reduction_method\"] == \"No Reduction\":\n",
    "        return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9870b343-5953-4c4c-85a0-692ee66f4a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def build_models(models, data):\n",
    "\n",
    "    model_pipelines = {}\n",
    "    for model in models:\n",
    "        model_param = data['design_state_data']['algorithms'][model]\n",
    "        \n",
    "        if model == \"RandomForestRegressor\":\n",
    "            model = RandomForestRegressor()\n",
    "            model_pipelines[\"RandomForestRegressor\"] = model\n",
    "    \n",
    "    \n",
    "        elif model == \"LinearRegression\":\n",
    "            model = LinearRegression()\n",
    "            model_pipelines[\"LinearRegression\"] = model\n",
    "        \n",
    "    \n",
    "        elif model == \"RidgeRegression\":\n",
    "            model = Ridge(\n",
    "                    alpha = float(model_param[\"regularization_term\"]))\n",
    "            model_pipelines[\"RidgeRegression\"] = model\n",
    "    \n",
    "        elif model == \"LassoRegression\":\n",
    "            model = Lasso(\n",
    "                    max_iter = int(model_param[\"max_iter\"]),\n",
    "                    alpha = float(model_param[\"regularization_term\"]))\n",
    "            model_pipelines[\"LassoRegression\"] = model\n",
    "    \n",
    "        elif model == \"ElasticNetRegression\":\n",
    "            model = ElasticNet(\n",
    "                    max_iter = int(model_param[\"max_iter\"]),\n",
    "                    alpha = float(model_param[\"regularization_term\"]))\n",
    "            model_pipelines[\"ElasticNetRegression\"] = model\n",
    "    \n",
    "        elif model == \"DecisionTreeRegressor\":\n",
    "            model = DecisionTreeRegressor(\n",
    "                    max_depth = int(model_param[\"max_depth\"]))\n",
    "            model_pipelines[\"DecisionTreeRegressor\"] = model\n",
    "\n",
    "    return model_pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49bc3513-8505-43fe-b07c-2a1b8609c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def grid_search_cv_pipeline(pipeline_obj,data):\n",
    "    for model in pipeline_obj:\n",
    "        model_param = data['design_state_data']['algorithms'][model]\n",
    "        if model == 'RandomForestRegressor':\n",
    "            reg = make_pipeline(StandardScaler(),GridSearchCV(\n",
    "                        estimator = pipeline_obj[model],\n",
    "                        param_grid = {'n_estimators'     : [int(model_param[\"min_trees\"])                      ,  int(model_param[\"max_trees\"])],\n",
    "                                      'max_depth'        : [int(model_param[\"min_depth\"])                      ,  int(model_param[\"max_depth\"])],\n",
    "                                      'min_samples_leaf' : [int(model_param[\"min_samples_per_leaf_min_value\"]) ,  int(model_param[\"min_samples_per_leaf_max_value\"])]\n",
    "                                     }\n",
    "            ))\n",
    "            pipeline_obj[model] = reg\n",
    "\n",
    "        #TEST LATER\n",
    "        elif model == \"LinearRegression\":\n",
    "            reg = make_pipeline(StandardScaler(),GridSearchCV(\n",
    "                        estimator = pipeline_obj[model],\n",
    "                        param_grid = {}\n",
    "            ))\n",
    "            pipeline_obj[model] = reg        \n",
    "    \n",
    "        elif model == \"RidgeRegression\":\n",
    "            reg = make_pipeline(StandardScaler(),GridSearchCV(\n",
    "                        estimator = pipeline_obj[model],\n",
    "                        param_grid = {'max_iter' : [int(model_param[\"min_iter\"])       ,   int(model_param[\"max_iter\"])],\n",
    "                                      'alpha'    : [float(model_param[\"min_regparam\"]) ,   float(model_param[\"max_regparam\"])]}\n",
    "            ))\n",
    "            pipeline_obj[model] = reg \n",
    "    \n",
    "        elif model == \"LassoRegression\":\n",
    "            reg = make_pipeline(StandardScaler(),GridSearchCV(\n",
    "                        estimator = pipeline_obj[model],\n",
    "                        param_grid = {'max_iter' : [int(model_param[\"min_iter\"])       ,   int(model_param[\"max_iter\"])],\n",
    "                                      'alpha'    : [float(model_param[\"min_regparam\"]) ,   float(model_param[\"max_regparam\"])]}\n",
    "            ))\n",
    "            pipeline_obj[model] = reg \n",
    "    \n",
    "        elif model == \"ElasticNetRegression\":\n",
    "            reg = make_pipeline(StandardScaler(),GridSearchCV(\n",
    "                        estimator = pipeline_obj[model],\n",
    "                        param_grid = {'max_iter' : [int(model_param[\"min_iter\"])        ,   int(model_param[\"max_iter\"])],\n",
    "                                      'alpha'    : [float(model_param[\"min_regparam\"])  ,   float(model_param[\"max_regparam\"])],\n",
    "                                      'l1_ratio' : [float(model_param[\"min_elasticnet\"]),   float(model_param[\"min_elasticnet\"])]}\n",
    "            ))\n",
    "            pipeline_obj[model] = reg \n",
    "    \n",
    "        elif model == \"DecisionTreeRegressor\":\n",
    "            reg = make_pipeline(StandardScaler(),GridSearchCV(\n",
    "                        estimator = pipeline_obj[model],\n",
    "                        param_grid = {'max_depth'        : [int(model_param[\"min_depth\"]) , int(model_param[\"max_depth\"])],\n",
    "                                      'min_samples_leaf' : model_param['min_samples_per_leaf']}\n",
    "            ))\n",
    "            pipeline_obj[model] = reg \n",
    "    return pipeline_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6458026b-6f59-4969-9775-2030353f02f0",
   "metadata": {},
   "source": [
    "## Read algoparams_from_ui.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e3ca102-31fe-469c-9471-d6d4b0443bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open(\"assets/algoparams_from_ui.json\", 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0293f3-aa9d-4629-a99f-f9ae86d6e3b7",
   "metadata": {},
   "source": [
    "## Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5ed2487-965b-455a-9f72-65d44672a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"assets/iris.csv\")\n",
    "target = data['design_state_data']['target']['target']\n",
    "prediction_type = data['design_state_data']['target']['prediction_type']\n",
    "features = data['design_state_data'][\"feature_handling\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9289ea-db85-427c-a1e0-974b72e11861",
   "metadata": {},
   "source": [
    "## Untransformed Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae8e28ac-367a-49e6-8264-0439a6fae77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf91a58d-68f3-43f2-a687-0bdb4d78ea5d",
   "metadata": {},
   "source": [
    "## Transformed Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0e8c290-739c-473e-adbb-2e4bd432cce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species_feature_1</th>\n",
       "      <th>species_feature_2</th>\n",
       "      <th>species_feature_3</th>\n",
       "      <th>species_feature_4</th>\n",
       "      <th>species_feature_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  species_feature_1  \\\n",
       "0           5.1          3.5           1.4          0.2                0.0   \n",
       "1           4.9          3.0           1.4          0.2                0.0   \n",
       "2           4.7          3.2           1.3          0.2                0.0   \n",
       "3           4.6          3.1           1.5          0.2                0.0   \n",
       "4           5.0          3.6           1.4          0.2                0.0   \n",
       "\n",
       "   species_feature_2  species_feature_3  species_feature_4  species_feature_5  \n",
       "0               -1.0                0.0                0.0                0.0  \n",
       "1               -1.0                0.0                0.0                0.0  \n",
       "2               -1.0                0.0                0.0                0.0  \n",
       "3               -1.0                0.0                0.0                0.0  \n",
       "4               -1.0                0.0                0.0                0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = transform_df(df, features)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79489398-4ec4-4de2-ae54-08ef9547e892",
   "metadata": {},
   "source": [
    "## Dataframe after feature reduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5975d146-8f40-4b7f-b36c-05d9ef9ed729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t3/tsyj7jb16t9d2546gfs_hpkm0000gn/T/ipykernel_15023/1925572757.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df[target] = df[target]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>petal_length</th>\n",
       "      <th>species_feature_2</th>\n",
       "      <th>species_feature_3</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   petal_length  species_feature_2  species_feature_3  sepal_width  \\\n",
       "0           1.4               -1.0                0.0          3.5   \n",
       "1           1.4               -1.0                0.0          3.0   \n",
       "2           1.3               -1.0                0.0          3.2   \n",
       "3           1.5               -1.0                0.0          3.1   \n",
       "4           1.4               -1.0                0.0          3.6   \n",
       "\n",
       "   petal_width  \n",
       "0          0.2  \n",
       "1          0.2  \n",
       "2          0.2  \n",
       "3          0.2  \n",
       "4          0.2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = reduce(target, df, data['design_state_data']['feature_reduction'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58be048-2b7a-41c4-8ca5-753bafd3e8c7",
   "metadata": {},
   "source": [
    "## Build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b84e8d2e-666d-4998-91fe-a41fcf49ac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"RandomForestRegressor\", \"GBTRegressor\", \"LinearRegression\", \"RidgeRegression\", \"LassoRegression\", \"ElasticNetRegression\", \"DecisionTreeRegressor\"]\n",
    "X = df.drop(columns = [target]).values\n",
    "y = df[target].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=0)\n",
    "\n",
    "model_pipelines = build_models(models,data)\n",
    "pipelines = grid_search_cv_pipeline(model_pipelines, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cca0df3-6e17-4f33-931d-dec0d787a533",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fe452c1-c378-4745-8185-9cc54a621f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForestRegressor : 0.9252343675951119\n",
      "Model metrics are : RandomForestRegressor(max_depth=20, min_samples_leaf=5, n_estimators=20)\n",
      "\n",
      "\n",
      "Accuracy of LinearRegression : 0.9341241341317029\n",
      "Model metrics are : LinearRegression()\n",
      "\n",
      "\n",
      "Accuracy of RidgeRegression : 0.9333368914639942\n",
      "Model metrics are : Ridge(alpha=0.8, max_iter=30)\n",
      "\n",
      "\n",
      "Accuracy of LassoRegression : 0.5103904656519349\n",
      "Model metrics are : Lasso(alpha=0.5, max_iter=30)\n",
      "\n",
      "\n",
      "Accuracy of ElasticNetRegression : 0.7542938487640625\n",
      "Model metrics are : ElasticNet(alpha=0.5, max_iter=30)\n",
      "\n",
      "\n",
      "Accuracy of DecisionTreeRegressor : 0.9083395073623918\n",
      "Model metrics are : DecisionTreeRegressor(max_depth=4, min_samples_leaf=6)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in pipelines:\n",
    "    pipelines[i].fit(X_train, y_train)\n",
    "    print(f\"Accuracy of {i} : {pipelines[i].score(X_test, y_test)}\")\n",
    "    best_estimator = pipelines[i].named_steps['gridsearchcv'].best_estimator_\n",
    "    print(f\"Model metrics are : {best_estimator}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
